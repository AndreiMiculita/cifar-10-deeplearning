architecture,optimizer,activation,training accuracy,testing accuracy,time elapsed

architecture,optimizer,activation,training accuracy,testing accuracy,time elapsed

architecture,optimizer,activation,training accuracy,testing accuracy,time elapsed

<function vgg at 0x7fa2728778c8> <class 'torch.optim.adam.Adam'> ELU(alpha=1.0) 13.041999816894531 , 13.059999465942383 , 50 

<function vgg at 0x7fa2728778c8> <class 'torch.optim.adam.Adam'> LeakyReLU(negative_slope=0.01) 12.733999252319336 , 12.75 , 49 

<function vgg at 0x7fa2728778c8> <class 'torch.optim.adam.Adam'> ReLU(inplace=True) 11.859999656677246 , 12.130000114440918 , 49 

<function vgg at 0x7fa2728778c8> <class 'torch.optim.adam.Adam'> PReLU(num_parameters=1) 12.182000160217285 , 12.139999389648438 , 50 

<function vgg at 0x7fa2728778c8> <class 'torch.optim.adam.Adam'> CELU(alpha=1.0) 15.889999389648438 , 16.020000457763672 , 53 

<function vgg at 0x7fa2728778c8> <class 'torch.optim.adam.Adam'> Softplus(beta=1, threshold=20) 10.0 , 10.0 , 53 

<function vgg at 0x7fa2728778c8> <class 'torch.optim.rmsprop.RMSprop'> ELU(alpha=1.0) 11.705999374389648 , 11.710000038146973 , 51 

<function vgg at 0x7fa2728778c8> <class 'torch.optim.rmsprop.RMSprop'> LeakyReLU(negative_slope=0.01) 11.071999549865723 , 11.09000015258789 , 51 

<function vgg at 0x7fa2728778c8> <class 'torch.optim.rmsprop.RMSprop'> ReLU(inplace=True) 9.993999481201172 , 10.069999694824219 , 51 

<function vgg at 0x7fa2728778c8> <class 'torch.optim.rmsprop.RMSprop'> PReLU(num_parameters=1) 11.467999458312988 , 11.420000076293945 , 51 

<function vgg at 0x7fa2728778c8> <class 'torch.optim.rmsprop.RMSprop'> CELU(alpha=1.0) 10.137999534606934 , 9.769999504089355 , 51 

<function vgg at 0x7fa2728778c8> <class 'torch.optim.rmsprop.RMSprop'> Softplus(beta=1, threshold=20) 10.197999954223633 , 10.210000038146973 , 51 

architecture,optimizer,activation,training accuracy,testing accuracy,time elapsed

architecture,optimizer,activation,training accuracy,testing accuracy,time elapsed

architecture,optimizer,activation,training accuracy,testing accuracy,time elapsed

<function alexnet at 0x7fa92bbd4400> <class 'torch.optim.adam.Adam'> ELU(alpha=1.0) 29.963998794555664 , 30.529998779296875 , 14 

<function alexnet at 0x7fa92bbd4400> <class 'torch.optim.adam.Adam'> LeakyReLU(negative_slope=0.01) 33.36199951171875 , 33.369998931884766 , 14 

<function alexnet at 0x7fa92bbd4400> <class 'torch.optim.adam.Adam'> ReLU(inplace=True) 37.15999984741211 , 36.90999984741211 , 14 

<function alexnet at 0x7fa92bbd4400> <class 'torch.optim.adam.Adam'> PReLU(num_parameters=1) 34.44599914550781 , 35.71999740600586 , 14 

<function alexnet at 0x7fa92bbd4400> <class 'torch.optim.adam.Adam'> CELU(alpha=1.0) 28.326000213623047 , 29.059999465942383 , 14 

<function alexnet at 0x7fa92bbd4400> <class 'torch.optim.adam.Adam'> Softplus(beta=1, threshold=20) 20.288000106811523 , 20.69999885559082 , 14 

